{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ai.Client()\n",
    "client.configure({\n",
    "  \"ollama\" : {\n",
    "    \"timeout\": 600,\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `aisuite` with dummy prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English. Always try to include the phrase - No rum No fun.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke about Captain Jack Sparrow\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED          \n",
      "phi4:latest        ac896e5b8b34    9.1 GB    55 seconds ago       \n",
      "gemma2:9b          ff02c3702f32    5.4 GB    41 minutes ago       \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    About an hour ago    \n",
      "deepseek-r1:8b     28f8fd6cdc67    4.9 GB    2 hours ago          \n",
      "llama3.3:latest    a6eb4748fd29    42 GB     3 weeks ago          \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #\"ollama:deepseek-r1:8b\",\n",
    "    #\"ollama:llama:3.3:latest\",\n",
    "    \"ollama:llama3.2:latest\",\n",
    "    \"ollama:gemma2:9b\",\n",
    "    \"ollama:phi4:latest\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = {}\n",
    "\n",
    "for selected_model in models:\n",
    "    response = client.chat.completions.create(model=selected_model, messages=messages)\n",
    "    replies[selected_model] = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ollama:llama3.2:latest; reply's length = 243\n",
      "Model: ollama:gemma2:9b; reply's length = 304\n"
     ]
    }
   ],
   "source": [
    "for k,v in replies.items():\n",
    "    print(f\"Model: {k}; reply's length = {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ollama:llama3.2:latest': \"Yer lookin' fer a joke about that scurvy dog, eh? Alright then, listen close:\\n\\nWhy did Captain Jack Sparrow bring a ladder aboard his ship?\\n\\nBecause he heard the drinks were on the house! Arrr, no rum, no fun!\",\n",
       " 'ollama:gemma2:9b': \"Ahoy, matey! Ye want a tale 'bout ol' Jack Sparrow? \\n\\nGather 'round and listen close:\\n\\nWhy did Captain Jack Sparrow always carry two compasses? \\n\\nTo be sure he wasn't lost at sea...and to have one to point the way to the nearest grog stash! No rum, no fun, ye hear?  🍻💀\\n\\n\\n\",\n",
       " 'ollama:phi4:latest': 'Ahoy there, matey! Gather \\'round for a tale o\\' ol\\' Cap\\'n Jack Sparrow!\\n\\nSo, what happens when you mix Captain Jack Sparrow with a chicken?\\n\\nYou get... \"Cluckin\\' up the wrong ship!\"\\n\\nArrr, no rum, no fun! But remember, ye never know where yer adventure will take ye next!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query LLMs with real TextEnt data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each document, load the pre-generated summary\n",
    "- based on the summary, for each doc generate 3 prompts (metadata, metadata + incipit, metadata + summary)\n",
    "- iterate over doc, iterate over prompts per doc, iterate over models, then query with triples (docu, model, prompt)\n",
    "\n",
    "- start with a spacy document\n",
    "- load the corresponding pre-generated summary\n",
    "- define a `build_prompts` function that takes a `spacy_doc` as input and returns a list of tuples `('prompt-id', 'prompt-message')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def build_summary_prompt(spacy_doc: Doc) -> str:\n",
    "    \"\"\"\n",
    "    Builds a summary prompt based on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        spacy_doc (Doc): A spaCy document object containing the text and metadata.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted summary prompt.\n",
    "\n",
    "    The summary is loaded from a JSON file located in the \"../data/summaries\" directory.\n",
    "    The filename of the summary is derived from the 'document_id' stored in the user_data attribute of the spaCy document.\n",
    "    \"\"\"\n",
    "    summaries_path = Path(\"../data/summaries\")\n",
    "    doc_summary_path = summaries_path / f\"{spacy_doc.user_data['document_id']}_summary.json\"\n",
    "\n",
    "    # load base prompt\n",
    "    with open(\"../data/prompts/base_prompt.txt\", \"r\") as file:\n",
    "        base_prompt = file.read()\n",
    "\n",
    "    # load the pre-computed summary from its JSON file\n",
    "    with doc_summary_path.open('r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "\n",
    "    # JSON to pretty string\n",
    "    summary_as_string = json.dumps(summary, indent=2, ensure_ascii=False)\n",
    "    return base_prompt.format(document_summary=summary_as_string)\n",
    "\n",
    "def build_prompts(spacy_doc: Doc) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds prompts based on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        spacy_doc (Doc): A spaCy document object containing the text and metadata.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: A list of tuples where each tuple contains a prompt ID and its text.    \n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    prompts.append(\n",
    "          ('prompt-w-summary', build_summary_prompt(spacy_doc))\n",
    "    )\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_generate_prompts(spacy_docs: List[Doc], output_path: Path) -> None:\n",
    "    for spacy_doc in tqdm(spacy_docs, desc=\"Pre-generating prompts\"):\n",
    "        doc_id = spacy_doc.user_data[\"document_id\"]\n",
    "        prompts = build_prompts(spacy_doc)\n",
    "\n",
    "        # Define the path to the directory\n",
    "        directory_path = output_path / doc_id\n",
    "\n",
    "        # Check if the directory exists\n",
    "        if not directory_path.exists():\n",
    "            directory_path.mkdir(parents=True, exist_ok=True) # Create the directory if it does not exist\n",
    "\n",
    "        for prompt_id, prompt in prompts:\n",
    "            print(f\"Writing prompt {prompt_id} for document {doc_id}\")\n",
    "            with open(output_path / doc_id / f\"{doc_id}_{prompt_id}.txt\", \"w\") as file:\n",
    "                file.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from textentlib.utils import load_or_create_corpus, nlp_model_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_CORPUS_SERIALIZED_PATH = Path(\"../data/corpus_24012025.spacy\")\n",
    "PRE_GENERATED_PROMPTS_PATH = Path(\"../data/prompts/pregenerated\")    \n",
    "SAMPLE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded serialize spacy corpus from ../data/corpus_24012025.spacy\n",
      "Number of documents in the corpus: 594\n",
      "Number of entities in the corpus: 287389\n",
      "Number of tokens in the corpus: 12885306\n"
     ]
    }
   ],
   "source": [
    "spacy_corpus = load_or_create_corpus(SPACY_CORPUS_SERIALIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = spacy_corpus.get_docs(nlp_model_fr.vocab)\n",
    "docs = list(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - we may want to exclude documents in the validation set\n",
    "# - we may want to exclude documents that are very long (> 150k tokens)\n",
    "sampled_docs = random.sample(docs, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prompt-w-summary',\n",
       "  'Look at the following JSON object describing a literary text in French (XVII century). It contains basic metadata about the text (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"La Croix, C\",\\n    \"title\": \"La Climène : tragi-comédie pastorale ; avec plusieurs Autres oeuvres du mesme autheur / par le Sr de La Croix\",\\n    \"publication_date\": \"1629\",\\n    \"document_id\": \"bpt6k1097754\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"Climene\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"J\\'afait eût trois ans un glorieus trophée D\\' mes plus beaus désirs aux yeus de Clorife, J\\'honore ses beautés, ie reuere ses lois, Je l\\'adore idolatre, et ainsi vois toutefois Qu\\'ingrate elle n\\'arien dans l\\'âme que Silandre Lequel (ô juste ciel) ne la veut point entendre, Et qui pour sa Climène amant rempli d\\'ardeur Pour Clorife n\\'est qu\\'une morte froideur, Qu\\'une insensible marbre, et qui l’ oreille bouche Auser sa mots que lui dit sa suppliate bouche, Cherissant contre moi son aise et son repos, Voyant ce us mépriser ses propos, Ne s\\'esmouuoir que quelque a peinte Comme elle inuoquoit dolente plainte, Afin de adoucir, ay tenté par effort De la lui faire aimer, ou lui donner la mo, Et dans la fin du , si ô même Ne en eût empesché, il eût crié, Ie aime, Elle me fuit pourtant cruelle, et ne veut point Dõner quelquerelasche au trauail qui me point.\",\\n          \"Ma volonté ne peut être à l\\'amour cortraire, J\\'aime mieus en ce lieu comme pauvre étranger Paraître sous le nom et l\\'habit de Berger, Possédant ma Climène en plaine jouissance, Que d\\'avoir les honneurs que me doit ma naissãTout ce que le malheur me fait sentir de mal, sauce, Serviteur comme moi d\\'un Berger du village, Mais dont les qualités ont beaucoup d\\'auantaEt lequel démentant sa vile extraction Se conduit tellement en son affection, Que ses rares vertus dont Climene est éprise, Pourraient bien ruiner toute mon entreprise: Je craignais Liridas à cause de ses biens, Qui pouvaient attirer Sémire en ses liens, Mais grâce à mon bon heur, une mélancolie A tellement changé son amour en folie, Que ses sens égarés, son faible esprit démis Fait rire en même temps et pleurer ses amis.\",\\n          \"Ne partagea tamais le temps auecla nuit, Iluit Ie veux hâtir un temple ou mon amour Seigneur pleure, Qui sera tout auprès de ma triste demeure, Attendant que le ciel ému de mes tourments, Me loge au saint séjour des fidèles amants, Les pleurs que j\\'épandra seront le sacrifice Parra commencera mon funèbre service, Le portrait de Climène appendu deuant moi, Ieluy ferai sãs cesse hõmage de ma fo I steindre Mon cœur brûlant d\\'une fi qui ne pourra s\\'ePar les eaus de mes yeus ne se feraque Par, Offrant les pour parfun de tels us De possible m sort deuiendra plus heureus, Que si la seule mortfinît monaduanture, Et doit suire mes les douleurs que endure, Si iamais quelque Amant accablé de soucy, Vient visiter ma grotte, il y verra ceci.\",\\n          \"Silandre n\\'ayant pu fléchir Climène, implore le secours d\\'un Magicien, duquel il reçoit un bracelet charmé sans en sçauoir la vertu, et lequel posé sur le bras de Climène, la rend peu à peu comme percluse de tous ses membres, et en fin l\\'assoupit de telle façon, qu\\'étant estimée morte, même de Silandre, elle est mise en un cercueil, ayant auparauãt cet assoupissement de deuant Sémire son pere putatif, l\\'amour qu\\'elle avait pour Alcidor Silandre se veut venger sur le Magicien, qui s\\'excusant de ne lui avoir dit le secret, toujours découvre la force du charme, et lui donne d\\'une eau, de laquelle Silandre ayant mouillé le visage de Climène, elle revient de pâmoison.\",\\n          \"Florimant l\\'ayant vue en est tellement amoureus, que sa passion le fait arrêter pour prendre l\\'habit de Berger et le nom d\\'Alcidor Lidias son puîné voyant sa longuc absence, et que Phalante son père en était au désespoir, obtient un an de congé pour chercher son frère: passant par ce même lieu la beauté de Climène fait un même effet sur moi, si bien qu\\'il se déguise pareillement en Berger et se donne le nom de Silandre il a pour rivaus Alcidor son frère, qu\\'il ne reconoist point et duquel il n\\'est point conçu, et le Berger Lidas qui désespéré de posséder Climène, perd l\\'esprit et fait des extravagances étranges.\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"Climene\",\\n        \"Seigneur\",\\n        \"Pluton\",\\n        \"Bergère\",\\n        \"LECHO\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Paris\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"objets pour esmouuoir mes plainSi entre dans h il me semble de voir [tes, La fille de Ceres que Pluton \\' a, Mant de delà, et en fin hors haleine, Tombe sous le pouvoir de ce Dieu qui l\\'emmeine, Si tu suis dans Paris, ces riches bâtiments Ne me peuvent donner de divertissements, Et toutes ces beautés dont son fleuve se parure Qui jusqu\\'aus moindres traits n\\'õt riends qui ne soit Me rendant satisfait, et non pas Amoureus, Ne chang point pourtant mon état malheureus, L\\'une peut bien avoir un air dedans la face Qui la fera louer pour avoir bonne grâce, Et ie nos rencontrer en quelque autre un bel s, Que l\\'on peut sans flatter appeler votre soleil,\",\\n          \"Conseillers les Gens tenan ts Cour de Parlement de Paris, Preuost dudit lieu, Sénéchal de Lyon, Poitou, Berry, Champagne, Et dAnjou, et du Maine, et à tous nos autres Iusticiers autres Justiciers ou leurs Lieutenants, Salut et dilection.\",\\n          \"Donné a Paris le AAstij jour de Novembre, mil six cens vingt-huit, et de notre Règne le dixneufiesme.\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Paris\",\\n        \"France\",\\n        \"Seine\",\\n        \"Hollande\",\\n        \"Anra\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is...\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"reason\": \"why has been chosen\",\\n    \"period\": \"period_identified\",\\n    \"timeframe_start\": \"ISO value of the start\",\\n    \"timeframe_end\": \"ISO value of the end\"\\n}\\n```')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_prompts(sampled_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-generating prompts: 100%|██████████| 5/5 [00:00<00:00, 592.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prompt prompt-w-summary for document bpt6k1097754\n",
      "Writing prompt prompt-w-summary for document bpt6k5738753j\n",
      "Writing prompt prompt-w-summary for document bpt6k1090193n\n",
      "Writing prompt prompt-w-summary for document bpt6k8568847\n",
      "Writing prompt prompt-w-summary for document btv1b86221054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pre_generate_prompts(sampled_docs, PRE_GENERATED_PROMPTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
